* Amazons
  Models here:

  - h1 - one of the first games/runs ever trained with gzero
  - h3 - a second attempt, was specifically for entering ICGA Computer Olympiad 2018
  - f1 - a recent 3 day (3 GPUs) run with small network, using new features.

  h1/h3 runs were with expert iteration.  No further training post ICGA.

  Special thanks to Richard Lorentz for entertaining mini competitions to evaluate the strength of
  models/bot on LG.

* elo graph
  Each model has ran a minimum of 100 games with a randomised matching algorithm continuous
  tournament.  Each match is configured with a small amount of noise, and 800 evaluations per move.

  - The y-axis is ELO.
  - The x-axis is somewhat arbitrary in terms of compute.  Each model produced has a numeric
    value, which goes up incrementally as training progresses.
  - random player has a fixed ELO of 500.

  [[elo.png]]



